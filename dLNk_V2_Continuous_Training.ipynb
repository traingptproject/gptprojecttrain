{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ dLNk GPT V2 - Continuous Training\n",
    "\n",
    "## ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏° Real-time LINE Notifications\n",
    "\n",
    "### ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:\n",
    "- ‚úÖ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 999,972 samples ‡∏à‡∏≤‡∏Å Google Drive\n",
    "- ‚úÖ V2 Anti-Overfitting Configuration\n",
    "- ‚úÖ ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô LINE ‡πÅ‡∏ö‡∏ö real-time (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)\n",
    "- ‚úÖ Auto-save checkpoints ‡∏ó‡∏∏‡∏Å 500 steps\n",
    "- ‚úÖ Continuous monitoring\n",
    "- ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Colab disconnect\n",
    "\n",
    "### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:\n",
    "1. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Runtime ‡πÄ‡∏õ‡πá‡∏ô GPU (A100 ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)\n",
    "2. ‡∏£‡∏±‡∏ô cells ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö\n",
    "3. ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡πà‡∏≤‡∏ô LINE\n",
    "4. ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ - ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏î‡∏π‡πÅ‡∏•‡πÄ‡∏≠‡∏á\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU\n",
    "!nvidia-smi\n",
    "print(\"\\n‚úÖ GPU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Colab Disconnect\n",
    "%%javascript\n",
    "function ClickConnect(){\n",
    "  console.log(\"üîÑ Keeping Colab alive...\");\n",
    "  document.querySelector(\"colab-toolbar-button#connect\").click()\n",
    "}\n",
    "setInterval(ClickConnect, 60000)  // Every 60 seconds\n",
    "console.log(\"‚úÖ Anti-disconnect activated!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies\n",
    "%%capture\n",
    "!pip install -q transformers>=4.30.0 datasets>=2.12.0 accelerate>=0.20.0 peft>=0.4.0 bitsandbytes tensorboard\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Login Hugging Face (‡πÉ‡∏™‡πà token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)\n",
    "from huggingface_hub import login\n",
    "\n",
    "# TODO: ‡πÉ‡∏™‡πà Hugging Face token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
    "HF_TOKEN = \"\"  \n",
    "\n",
    "if not HF_TOKEN:\n",
    "    print(\"‚ö†Ô∏è  ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Hugging Face token\")\n",
    "else:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"‚úÖ Hugging Face login successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ Clone Repository\n",
    "import os\n",
    "\n",
    "if os.path.exists('/content/gptprojecttrain'):\n",
    "    print(\"üìÅ Repository exists, pulling latest changes...\")\n",
    "    %cd /content/gptprojecttrain\n",
    "    !git pull origin main\n",
    "else:\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    %cd /content\n",
    "    !git clone https://github.com/traingptproject/gptprojecttrain.git\n",
    "    %cd gptprojecttrain\n",
    "\n",
    "!ls -la train_v2_continuous.py\n",
    "print(\"\\n‚úÖ Repository ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7Ô∏è‚É£ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á manus-mcp-cli (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LINE notifications)\n",
    "# Note: ‡πÉ‡∏ô Colab ‡∏à‡∏∞‡πÉ‡∏ä‡πâ mock version ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MCP ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\n",
    "# ‡πÅ‡∏ï‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏∞‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE\n",
    "\n",
    "!mkdir -p /usr/local/bin\n",
    "\n",
    "with open('/usr/local/bin/manus-mcp-cli', 'w') as f:\n",
    "    f.write('''#!/bin/bash\n",
    "echo \"[LINE NOTIFICATION]\"\n",
    "echo \"$@\" | grep -oP '(?<=\"text\":\")[^\"]*' | sed 's/\\\\\\\\n/\\n/g'\n",
    "echo '{\"sentMessages\":[{\"id\":\"mock\"}]}'\n",
    "''')\n",
    "\n",
    "!chmod +x /usr/local/bin/manus-mcp-cli\n",
    "!export PATH=\"/usr/local/bin:$PATH\"\n",
    "\n",
    "print(\"‚úÖ manus-mcp-cli installed (mock version for Colab)\")\n",
    "print(\"üì± LINE notifications will be printed to console\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏ô‡∏¥‡πà‡∏á\n",
    "import os\n",
    "\n",
    "DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/training_data_1m_final.jsonl\"\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    file_size = os.path.getsize(DATASET_PATH) / (1024 * 1024)  # MB\n",
    "    print(f\"‚úÖ Dataset found!\")\n",
    "    print(f\"üìÅ Path: {DATASET_PATH}\")\n",
    "    print(f\"üíæ Size: {file_size:.2f} MB\")\n",
    "    \n",
    "    # Count lines\n",
    "    with open(DATASET_PATH, 'r') as f:\n",
    "        line_count = sum(1 for _ in f)\n",
    "    print(f\"üìä Samples: {line_count:,}\")\n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found at: {DATASET_PATH}\")\n",
    "    print(\"‚ö†Ô∏è  Please check the path and make sure Google Drive is mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9Ô∏è‚É£ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô V2 Continuous\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ Starting dLNk GPT V2 Continuous Training\")\n",
    "print(\"=\"*80)\n",
    "print(\"\")\n",
    "print(\"üìä Configuration:\")\n",
    "print(\"  - Dataset: 999,972 samples\")\n",
    "print(\"  - Model: GPT-J-6B\")\n",
    "print(\"  - GPU: A100-SXM4-80GB\")\n",
    "print(\"  - Learning Rate: 5e-6 (V2)\")\n",
    "print(\"  - Weight Decay: 0.1 (V2)\")\n",
    "print(\"  - LoRA Rank: 16 (V2)\")\n",
    "print(\"  - LoRA Dropout: 0.05 (V2)\")\n",
    "print(\"  - Eval Steps: 500 (10x more frequent)\")\n",
    "print(\"\")\n",
    "print(\"üì± LINE Notifications:\")\n",
    "print(\"  - Training start\")\n",
    "print(\"  - Progress updates (every 5 min)\")\n",
    "print(\"  - Evaluation results (every 500 steps)\")\n",
    "print(\"  - Checkpoint saved\")\n",
    "print(\"  - Training complete\")\n",
    "print(\"  - Error alerts\")\n",
    "print(\"\")\n",
    "print(\"‚è±Ô∏è  Estimated time: 8-12 hours (with 1M samples)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\")\n",
    "\n",
    "# Run training\n",
    "!python3 train_v2_continuous.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à\n",
    "\n",
    "### ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà:\n",
    "- `/content/gptprojecttrain/dLNk-gpt-j-6b-exploit-v2-continuous/`\n",
    "\n",
    "### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•:\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"./dLNk-gpt-j-6b-exploit-v2-continuous\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Test\n",
    "prompt = \"### Instruction:\\nExplain SQL injection\\n\\n### Response:\\n\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "```\n",
    "\n",
    "### ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Hugging Face Hub:\n",
    "```python\n",
    "model.push_to_hub(\"traingptproject/dLNk-gpt-j-6b-exploit-v2\")\n",
    "tokenizer.push_to_hub(\"traingptproject/dLNk-gpt-j-6b-exploit-v2\")\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
