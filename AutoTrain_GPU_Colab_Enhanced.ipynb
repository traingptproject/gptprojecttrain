{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# dLNk GPT - Enhanced Training Workflow\n",
        "\n",
        "This notebook implements a comprehensive training workflow with:\n",
        "- \u2705 **Early Stopping** - Prevents overfitting\n",
        "- \u2705 **Learning Rate Scheduling** - Optimizes training\n",
        "- \u2705 **Real-time Monitoring** - TensorBoard integration\n",
        "- \u2705 **Quality Assurance** - Automated testing each epoch\n",
        "- \u2705 **Resource Monitoring** - GPU/Memory tracking\n",
        "\n",
        "**Requirements:**\n",
        "- GPU Runtime (T4 recommended, A100 for faster training)\n",
        "- Hugging Face Token\n",
        "- 12-16 hours training time (T4)\n",
        "\n",
        "**Steps:**\n",
        "1. Enable GPU: Runtime \u2192 Change runtime type \u2192 GPU\n",
        "2. Run all cells in order\n",
        "3. Monitor with TensorBoard"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers>=4.30.0 datasets>=2.12.0 accelerate>=0.20.0 peft>=0.4.0 bitsandbytes tensorboard\n",
        "print(\"\u2705 All packages installed\")"
      ],
      "metadata": {
        "id": "install_packages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Login to Hugging Face"
      ],
      "metadata": {
        "id": "login"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Enter your Hugging Face token here\n",
        "HF_TOKEN = \"\"  # Paste your token between the quotes\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    print(\"\u26a0\ufe0f  Please enter your Hugging Face token above\")\n",
        "else:\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"\u2705 Logged in to Hugging Face\")"
      ],
      "metadata": {
        "id": "hf_login"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Clone Repository and Setup Files"
      ],
      "metadata": {
        "id": "clone_repo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/traingptproject/gptprojecttrain.git\n",
        "%cd gptprojecttrain\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "clone"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Configure Training (Optional)"
      ],
      "metadata": {
        "id": "config"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View current configuration\n",
        "!cat training_config.py | head -50\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"You can modify training_config.py to adjust hyperparameters\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "view_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Launch TensorBoard"
      ],
      "metadata": {
        "id": "tensorboard"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TensorBoard extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Launch TensorBoard\n",
        "%tensorboard --logdir ./logs --port 6006\n",
        "\n",
        "print(\"\\n\u2705 TensorBoard launched!\")\n",
        "print(\"\ud83d\udcca You can view training metrics in real-time above\")"
      ],
      "metadata": {
        "id": "launch_tensorboard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Start Training\n",
        "\n",
        "**This will take 12-16 hours on T4 GPU**\n",
        "\n",
        "The training includes:\n",
        "- Early stopping (stops if validation loss doesn't improve for 3 epochs)\n",
        "- Learning rate scheduling (cosine schedule with warmup)\n",
        "- Quality assurance tests after each epoch\n",
        "- Automatic checkpoint management\n",
        "- Real-time metrics logging to TensorBoard"
      ],
      "metadata": {
        "id": "train"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "!python train_enhanced.py"
      ],
      "metadata": {
        "id": "start_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. View Training Results"
      ],
      "metadata": {
        "id": "results"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View metrics history\n",
        "import json\n",
        "\n",
        "with open('./training_output/metrics_history.json', 'r') as f:\n",
        "    metrics = json.load(f)\n",
        "\n",
        "print(f\"Total training steps: {len(metrics)}\")\n",
        "print(f\"\\nFinal metrics:\")\n",
        "print(json.dumps(metrics[-1], indent=2))"
      ],
      "metadata": {
        "id": "view_metrics"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View QA test results from last epoch\n",
        "import os\n",
        "import json\n",
        "\n",
        "qa_dir = './training_output/qa_results'\n",
        "qa_files = sorted(os.listdir(qa_dir))\n",
        "latest_qa = os.path.join(qa_dir, qa_files[-1])\n",
        "\n",
        "with open(latest_qa, 'r') as f:\n",
        "    qa_results = json.load(f)\n",
        "\n",
        "print(f\"QA Results from Epoch {qa_results['epoch']}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, test in enumerate(qa_results['tests'], 1):\n",
        "    print(f\"\\n[Test {i}]\")\n",
        "    print(f\"Prompt: {test['prompt']}\")\n",
        "    print(f\"Response: {test['response'][:200]}...\")\n",
        "    print(f\"Time: {test['generation_time']:.2f}s\")"
      ],
      "metadata": {
        "id": "view_qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Test the Trained Model"
      ],
      "metadata": {
        "id": "test"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "print(\"Loading trained model...\")\n",
        "\n",
        "model_path = \"./training_output/final_model\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "print(\"\u2705 Model loaded!\\n\")\n",
        "\n",
        "def generate_response(prompt, max_tokens=200):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test\n",
        "test_prompt = \"Write a Python function to calculate fibonacci numbers:\"\n",
        "print(f\"Prompt: {test_prompt}\")\n",
        "print(\"=\"*80)\n",
        "response = generate_response(test_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "test_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Push to Hugging Face Hub (Optional)\n",
        "\n",
        "If you didn't enable `push_to_hub` in the config, you can manually push the model here."
      ],
      "metadata": {
        "id": "push"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model to Hub\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "model_path = \"./training_output/final_model\"\n",
        "repo_id = \"dlnkgpt/dlnkgpt-uncensored\"  # Change to your repo\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=model_path,\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        ")\n",
        "\n",
        "print(f\"\u2705 Model pushed to: https://huggingface.co/{repo_id}\")"
      ],
      "metadata": {
        "id": "push_to_hub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "### Training Complete! \ud83c\udf89\n",
        "\n",
        "**What was accomplished:**\n",
        "- \u2705 Model trained with early stopping\n",
        "- \u2705 Validation loss monitored throughout\n",
        "- \u2705 Quality assurance tests run each epoch\n",
        "- \u2705 Best checkpoint automatically selected\n",
        "- \u2705 Comprehensive metrics logged\n",
        "\n",
        "**Next Steps:**\n",
        "1. Review TensorBoard metrics\n",
        "2. Check QA test results\n",
        "3. Test the model with your own prompts\n",
        "4. Deploy to production or push to Hub\n",
        "\n",
        "**Files Created:**\n",
        "- `./training_output/final_model/` - Best model checkpoint\n",
        "- `./training_output/metrics_history.json` - All training metrics\n",
        "- `./training_output/qa_results/` - Quality assurance test results\n",
        "- `./logs/` - TensorBoard logs"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}