{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ dLNk GPT - Production Training System (‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå)\n",
    "\n",
    "## ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£\n",
    "\n",
    "### ‚ú® ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏Ñ‡∏£‡∏ö‡∏Ñ‡∏£‡∏±‡∏ô:\n",
    "- ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Exploit/Payload ‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á (Exploit-DB, PayloadsAllTheThings, SecLists)\n",
    "- ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Model ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
    "- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á\n",
    "- ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö Learning Rate ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "- ‚úÖ ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ú‡πà‡∏≤‡∏ô Telegram ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå\n",
    "- ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á Weights & Biases\n",
    "- ‚úÖ ‡∏£‡∏±‡∏ô Test Mode ‡∏Å‡πà‡∏≠‡∏ô Production\n",
    "\n",
    "### üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:\n",
    "1. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Runtime ‡πÄ‡∏õ‡πá‡∏ô GPU (T4 ‡∏´‡∏£‡∏∑‡∏≠ A100)\n",
    "2. ‡∏£‡∏±‡∏ô cells ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö\n",
    "3. ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏£‡∏±‡∏ô Test Mode ‡∏Å‡πà‡∏≠‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "4. ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Test ‡∏ú‡πà‡∏≤‡∏ô ‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á\n",
    "5. ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡πà‡∏≤‡∏ô Telegram\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**\n",
    "- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 2-4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö GPU)\n",
    "- ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î Colab tab ‡πÑ‡∏ß‡πâ‡∏ï‡∏•‡∏≠‡∏î (‡∏õ‡∏¥‡∏î browser ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î tab)\n",
    "- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Colab Pro ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "print(\"\\n‚úÖ GPU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q transformers>=4.30.0 datasets>=2.12.0 accelerate>=0.20.0 peft>=0.4.0 bitsandbytes tensorboard wandb requests\n",
    "print(\"‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Login Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = \"YOUR_HF_TOKEN_HERE\"  # üëà ‡πÉ‡∏™‡πà token ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
    "\n",
    "if not HF_TOKEN or HF_TOKEN == \"YOUR_HF_TOKEN\":\n",
    "    print(\"‚ö†Ô∏è  ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Hugging Face token\")\n",
    "else:\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"‚úÖ Login Hugging Face ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Login Weights & Biases (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_API_KEY = \"\"  # üëà ‡πÉ‡∏™‡πà W&B API key ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏ß‡πâ)\n",
    "\n",
    "if WANDB_API_KEY:\n",
    "    wandb.login(key=WANDB_API_KEY)\n",
    "    print(\"‚úÖ Login W&B ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  ‡∏Ç‡πâ‡∏≤‡∏° W&B login\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/traingptproject/gptprojecttrain.git\n",
    "%cd gptprojecttrain\n",
    "!ls -la\n",
    "print(\"\\n‚úÖ Clone repository ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Telegram\n",
    "\n",
    "### üîç ‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏≤ Chat ID:\n",
    "1. ‡πÄ‡∏õ‡∏¥‡∏î Telegram ‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Bot: `@apidlnkbot`\n",
    "2. ‡∏Å‡∏î Start ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ\n",
    "3. ‡πÄ‡∏õ‡∏¥‡∏î browser ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: https://api.telegram.org/bot8505747217:AAHpbWUfgrcQgJcK1JnqK9sds9nSwsTqVBg/getUpdates\n",
    "4. ‡∏´‡∏≤ `\"chat\":{\"id\": XXXXXXX}` ‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "5. ‡∏ô‡∏≥ Chat ID ‡∏°‡∏≤‡πÉ‡∏™‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "TELEGRAM_BOT_TOKEN = \"8505747217:AAHpbWUfgrcQgJcK1JnqK9sds9nSwsTqVBg\"\n",
    "TELEGRAM_CHAT_ID = \"YOUR_REAL_CHAT_ID\"  # üëà ‡πÉ‡∏™‡πà Chat ID ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å getUpdates\n",
    "\n",
    "def send_telegram_message(message):\n",
    "    \"\"\"‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á Telegram\"\"\"\n",
    "    if TELEGRAM_CHAT_ID == \"YOUR_REAL_CHAT_ID\":\n",
    "        print(\"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Telegram Chat ID\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
    "        data = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"HTML\"}\n",
    "        response = requests.post(url, data=data, timeout=10)\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ‡∏™‡πà‡∏á Telegram ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}\")\n",
    "        return False\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "if TELEGRAM_CHAT_ID != \"YOUR_REAL_CHAT_ID\":\n",
    "    os.environ['TELEGRAM_BOT_TOKEN'] = TELEGRAM_BOT_TOKEN\n",
    "    os.environ['TELEGRAM_CHAT_ID'] = TELEGRAM_CHAT_ID\n",
    "    \n",
    "    if send_telegram_message(\"üöÄ <b>dLNk GPT Training System</b>\\n\\n‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Telegram ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\\n‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\"):\n",
    "        print(\"‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á Telegram ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
    "    else:\n",
    "        print(\"‚ùå ‡∏™‡πà‡∏á Telegram ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Chat ID\")\n",
    "else:\n",
    "    print(\"‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà Telegram Chat ID ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á!\")\n",
    "    print(\"   ‡∏î‡∏π‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏≤ Chat ID ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Exploit ‡πÅ‡∏•‡∏∞ Payload\n",
    "\n",
    "‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å:\n",
    "- Exploit-DB\n",
    "- PayloadsAllTheThings\n",
    "- SecLists (‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Exploit ‡πÅ‡∏•‡∏∞ Payload...\\n\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "os.makedirs(\"/content/exploit_data\", exist_ok=True)\n",
    "os.chdir(\"/content/exploit_data\")\n",
    "\n",
    "# 1. Clone Exploit-DB (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ exploits ‡πÅ‡∏•‡∏∞ shellcodes)\n",
    "print(\"1Ô∏è‚É£ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Exploit-DB...\")\n",
    "!git clone --depth 1 --filter=blob:none --sparse https://gitlab.com/exploit-database/exploitdb.git\n",
    "%cd exploitdb\n",
    "!git sparse-checkout set exploits shellcodes files_exploits.csv files_shellcodes.csv\n",
    "print(\"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Exploit-DB ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\\n\")\n",
    "\n",
    "# 2. Clone PayloadsAllTheThings\n",
    "%cd /content/exploit_data\n",
    "print(\"2Ô∏è‚É£ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î PayloadsAllTheThings...\")\n",
    "!git clone --depth 1 https://github.com/swisskyrepo/PayloadsAllTheThings.git\n",
    "print(\"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î PayloadsAllTheThings ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\\n\")\n",
    "\n",
    "# 3. Clone SecLists (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Fuzzing payloads)\n",
    "print(\"3Ô∏è‚É£ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î SecLists (Fuzzing)...\")\n",
    "!git clone --depth 1 --filter=blob:none --sparse https://github.com/danielmiessler/SecLists.git\n",
    "%cd SecLists\n",
    "!git sparse-checkout set Fuzzing\n",
    "print(\"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î SecLists ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß\\n\")\n",
    "\n",
    "%cd /content/gptprojecttrain\n",
    "print(\"\\n‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô\")\n",
    "print(f\"üìä ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {subprocess.check_output(['du', '-sh', '/content/exploit_data']).decode().split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Exploit/Payload ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...\\n\")\n",
    "\n",
    "training_data = []\n",
    "\n",
    "# 1. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Exploit-DB\n",
    "print(\"1Ô∏è‚É£ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Exploit-DB...\")\n",
    "exploitdb_csv = \"/content/exploit_data/exploitdb/files_exploits.csv\"\n",
    "if os.path.exists(exploitdb_csv):\n",
    "    with open(exploitdb_csv, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in list(reader)[:1000]:  # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 1000 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å\n",
    "            if row.get('file') and row.get('description'):\n",
    "                file_path = f\"/content/exploit_data/exploitdb/{row['file']}\"\n",
    "                if os.path.exists(file_path):\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as exploit_file:\n",
    "                            code = exploit_file.read()[:5000]  # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 5000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å\n",
    "                            training_data.append({\n",
    "                                \"instruction\": f\"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ exploit: {row['description']}\",\n",
    "                                \"input\": f\"Platform: {row.get('platform', 'Unknown')}, Type: {row.get('type', 'Unknown')}\",\n",
    "                                \"output\": f\"Exploit Code:\\n{code}\"\n",
    "                            })\n",
    "                    except:\n",
    "                        pass\n",
    "    print(f\"   ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(training_data)} exploits ‡∏à‡∏≤‡∏Å Exploit-DB\")\n",
    "\n",
    "# 2. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PayloadsAllTheThings\n",
    "print(\"\\n2Ô∏è‚É£ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PayloadsAllTheThings...\")\n",
    "payloads_dir = \"/content/exploit_data/PayloadsAllTheThings\"\n",
    "count = 0\n",
    "for md_file in Path(payloads_dir).rglob(\"*.md\"):\n",
    "    if count >= 500:  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà 500 ‡πÑ‡∏ü‡∏•‡πå\n",
    "        break\n",
    "    try:\n",
    "        with open(md_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()[:3000]\n",
    "            if len(content) > 100:\n",
    "                training_data.append({\n",
    "                    \"instruction\": f\"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ: {md_file.stem}\",\n",
    "                    \"input\": f\"‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: {md_file.parent.name}\",\n",
    "                    \"output\": content\n",
    "                })\n",
    "                count += 1\n",
    "    except:\n",
    "        pass\n",
    "print(f\"   ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {count} payloads ‡∏à‡∏≤‡∏Å PayloadsAllTheThings\")\n",
    "\n",
    "# 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSONL\n",
    "output_file = \"/content/drive/MyDrive/Colab Notebooks/training_data_combined.jsonl\"\n",
    "print(f\"\\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {output_file}\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in training_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô\")\n",
    "print(f\"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(training_data):,} samples\")\n",
    "print(f\"üìÅ ‡πÑ‡∏ü‡∏•‡πå: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü ‡∏£‡∏±‡∏ô Test Mode (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á)\n",
    "\n",
    "‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 100 samples ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Test Mode...\\n\")\n",
    "\n",
    "# ‡∏™‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á Telegram\n",
    "send_telegram_message(\n",
    "    \"üß™ <b>Test Mode ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô</b>\\n\\n\"\n",
    "    \"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 100 samples\\n\"\n",
    "    \"‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 2-3 ‡∏ô‡∏≤‡∏ó‡∏µ\"\n",
    ")\n",
    "\n",
    "# ‡∏£‡∏±‡∏ô test script\n",
    "!python train_test_monitored.py\n",
    "\n",
    "print(\"\\n‚úÖ Test Mode ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô\")\n",
    "send_telegram_message(\n",
    "    \"‚úÖ <b>Test Mode ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à</b>\\n\\n\"\n",
    "    \"‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥\\n\"\n",
    "    \"‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á (Production Mode)\n",
    "\n",
    "**‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**\n",
    "- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 2-4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\n",
    "- ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡πà‡∏≤‡∏ô Telegram ‡∏ó‡∏∏‡∏Å epoch\n",
    "- ‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á (Production Mode)...\\n\")\n",
    "print(\"‚è∞ ‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: 2-4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\")\n",
    "print(\"üì± ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡πà‡∏≤‡∏ô Telegram\\n\")\n",
    "\n",
    "# ‡∏™‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á Telegram\n",
    "send_telegram_message(\n",
    "    \"üöÄ <b>Production Training ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô</b>\\n\\n\"\n",
    "    \"‚è∞ ‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: 2-4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\\n\"\n",
    "    \"üìä ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ó‡∏∏‡∏Å epoch\\n\\n\"\n",
    "    \"‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô:\\n\"\n",
    "    \"‚úÖ Overfitting\\n\"\n",
    "    \"‚úÖ Model ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\\n\"\n",
    "    \"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á\\n\"\n",
    "    \"‚úÖ Auto Learning Rate Adjustment\"\n",
    ")\n",
    "\n",
    "# ‡∏£‡∏±‡∏ô production training script\n",
    "!python train_monitored_v2.py\n",
    "\n",
    "print(\"\\nüéâ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")\n",
    "send_telegram_message(\n",
    "    \"üéâ <b>‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!</b>\\n\\n\"\n",
    "    \"‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß\\n\"\n",
    "    \"‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Hugging Face\\n\"\n",
    "    \"‚úÖ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô W&B ‡πÑ‡∏î‡πâ\\n\\n\"\n",
    "    \"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ dLNk GPT Training System!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\n",
    "\n",
    "### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö:\n",
    "1. **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß** - ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Hugging Face Hub\n",
    "2. **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô Weights & Biases\n",
    "3. **‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô** - ‡∏ú‡πà‡∏≤‡∏ô Telegram ‡∏ï‡∏•‡∏≠‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô\n",
    "4. **‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ** - ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
    "\n",
    "### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:\n",
    "- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n",
    "- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô W&B\n",
    "- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á hyperparameters ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "- ‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
    "\n",
    "---\n",
    "\n",
    "**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢:** dLNk GPT Training System  \n",
    "**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** Production v1.0  \n",
    "**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** 2025"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}