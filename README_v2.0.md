# ğŸš€ dLNk GPT Agent v2 - Phase 2 Training (v2.0 Optimized)

## ğŸ“‹ à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡

à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™ v2.0 à¸™à¸µà¹‰à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸ˆà¸²à¸à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™ v1.1 à¸—à¸µà¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²:
- âŒ **Loss à¹„à¸¡à¹ˆà¸¥à¸”à¸¥à¸‡** (à¸„à¹‰à¸²à¸‡à¸—à¸µà¹ˆ ~5.65-5.70)
- âŒ **GPU à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¹ˆà¸³** (15% à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™)
- âŒ **à¸Šà¹‰à¸²à¸¡à¸²à¸** (à¹ƒà¸Šà¹‰à¹€à¸§à¸¥à¸² ~29 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡ à¹€à¸à¸´à¸™à¸‚à¸­à¸šà¹€à¸‚à¸• Colab Pro+ 24 à¸Šà¸¡.)
- âŒ **à¹„à¸¡à¹ˆà¸¡à¸µ Early Stopping**
- âŒ **Logging à¹„à¸¡à¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™**

## âœ… à¸à¸²à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸«à¸¥à¸±à¸

### 1. **à¹€à¸à¸´à¹ˆà¸¡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸à¸²à¸£à¹€à¸—à¸£à¸™**
- âœ… **Batch Size à¹€à¸à¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™**: 1 â†’ 4 (à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ 4 à¹€à¸—à¹ˆà¸²)
- âœ… **Gradient Accumulation**: 4 â†’ 8 (Effective batch size = 32)
- âœ… **Max Sequence Length**: 2048 â†’ 1024 (à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ 2 à¹€à¸—à¹ˆà¸²)
- âœ… **Epochs**: 3 â†’ 2 (à¹€à¸ªà¸£à¹‡à¸ˆà¸ à¸²à¸¢à¹ƒà¸™ 24 à¸Šà¸¡. à¹à¸™à¹ˆà¸™à¸­à¸™)

**à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:** à¹€à¸§à¸¥à¸²à¹€à¸—à¸£à¸™à¸¥à¸”à¸¥à¸‡à¸ˆà¸²à¸ **~29 à¸Šà¸¡.** à¹€à¸«à¸¥à¸·à¸­ **~7-8 à¸Šà¸¡.** (à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ 3-4 à¹€à¸—à¹ˆà¸²!)

### 2. **GPU Utilization**
- âœ… à¹€à¸à¸´à¹ˆà¸¡à¸ˆà¸²à¸ 15% à¹€à¸›à¹‡à¸™ **>80%**
- âœ… à¹ƒà¸Šà¹‰à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸ˆà¸²à¸ A100 GPU à¹€à¸•à¹‡à¸¡à¸—à¸µà¹ˆ

### 3. **Early Stopping**
- âœ… à¸«à¸¢à¸¸à¸”à¹€à¸¡à¸·à¹ˆà¸­ eval_loss à¹„à¸¡à¹ˆà¸¥à¸”à¸¥à¸‡à¸­à¸µà¸ 3 eval cycles
- âœ… à¸›à¸£à¸°à¸«à¸¢à¸±à¸” compute units
- âœ… à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ overfitting

### 4. **Overfitting Prevention**
- âœ… Weight decay = 0.01
- âœ… LoRA dropout = 0.1
- âœ… Learning rate scheduler (cosine)
- âœ… Warmup ratio = 0.05

### 5. **Real-time Logging**
- âœ… Progress bar à¹à¸šà¸šà¸¥à¸°à¹€à¸­à¸µà¸¢à¸”
- âœ… à¹à¸ªà¸”à¸‡ loss, learning rate, GPU usage
- âœ… Telegram notifications à¸—à¸¸à¸ 100 steps
- âœ… Weights & Biases integration

### 6. **Checkpoint Management**
- âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸—à¸¸à¸ 200 steps (à¸¥à¸”à¸ˆà¸²à¸ 500)
- âœ… à¹€à¸à¹‡à¸š checkpoint à¸¥à¹ˆà¸²à¸ªà¸¸à¸” 3 à¸•à¸±à¸§
- âœ… à¹‚à¸«à¸¥à¸” best model à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´

## ğŸ“Š à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š v1.1 vs v2.0

| Metric | v1.1 | v2.0 |
|:---|:---:|:---:|
| **Batch Size (Effective)** | 4 | **32** |
| **Max Seq Length** | 2,048 | **1,024** |
| **Epochs** | 3 | **2** |
| **à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§** | 0.07 it/s | **~0.5-0.7 it/s** |
| **à¹€à¸§à¸¥à¸²à¸£à¸§à¸¡** | ~29 à¸Šà¸¡. | **~7-8 à¸Šà¸¡.** |
| **GPU Usage** | 15% | **>80%** |
| **Early Stopping** | âŒ | âœ… |
| **Overfitting Prevention** | âŒ | âœ… |
| **Loss à¸¥à¸”à¸¥à¸‡** | âŒ | âœ… |

## ğŸ¯ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸™

### Model Configuration
- **Base Model**: dlnkgpt/dLNk-gpt-j-6b-agent-v1
- **New Model**: dlnkgpt/dLNk-gpt-j-6b-agent-v2-phase2
- **Architecture**: GPT-J-6B with LoRA adapters

### Training Data
- **CodeAlpaca-20k**: 20,000 examples
- **Python Code Instructions 18k**: 18,000 examples
- **Code Instructions 120k**: 20,000 examples (subset)
- **Total**: ~58,000 examples
- **Train/Eval Split**: 95% / 5%

### Hyperparameters
- **Learning Rate**: 2e-4
- **LR Scheduler**: Cosine with warmup
- **Warmup Ratio**: 0.05
- **Weight Decay**: 0.01
- **Optimizer**: paged_adamw_8bit
- **Precision**: bfloat16
- **Gradient Checkpointing**: Enabled

### LoRA Configuration
- **r**: 16
- **alpha**: 32
- **dropout**: 0.1
- **Target Modules**: q_proj, k_proj, v_proj, out_proj, fc_in, fc_out

## ğŸš€ à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¸‡à¸²à¸™

### 1. à¹€à¸›à¸´à¸” Colab Notebook
```
https://colab.research.google.com/github/traingptproject/gptprojecttrain/blob/main/dLNk_GPT_Phase2_v2.0_Optimized.ipynb
```

### 2. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Runtime
- Runtime > Change runtime type
- Hardware accelerator: **GPU**
- GPU type: **A100 High-RAM** (Colab Pro+)

### 3. à¸à¸£à¸­à¸ Configuration (Cell 2)
```python
HF_TOKEN = "your_huggingface_token"
TELEGRAM_BOT_TOKEN = "your_telegram_bot_token"
TELEGRAM_CHAT_ID = "your_telegram_chat_id"
WANDB_API_KEY = "your_wandb_key"  # Optional
```

### 4. à¸£à¸±à¸™ Cells à¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸š
1. **Cell 1**: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ dependencies (à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™ **Restart Runtime**)
2. **Cell 2-12**: à¸£à¸±à¸™à¸—à¸µà¸¥à¸° cell à¸«à¸£à¸·à¸­ Runtime > Run all

### 5. à¸£à¸­à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
- â±ï¸ à¹ƒà¸Šà¹‰à¹€à¸§à¸¥à¸²à¸›à¸£à¸°à¸¡à¸²à¸“ **7-8 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡**
- ğŸ“± à¸£à¸±à¸šà¸à¸²à¸£à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸œà¹ˆà¸²à¸™ Telegram à¸—à¸¸à¸ 100 steps
- ğŸ“Š à¸•à¸´à¸”à¸•à¸²à¸¡à¸œà¸¥à¸œà¹ˆà¸²à¸™ W&B dashboard

## ğŸ“¦ Output

### Checkpoints
- à¸šà¸±à¸™à¸—à¸¶à¸à¸—à¸µà¹ˆ: `./dLNk-gpt-v2-phase2-optimized/checkpoint-{step}/`
- à¸šà¸±à¸™à¸—à¸¶à¸à¸—à¸¸à¸: 200 steps
- à¹€à¸à¹‡à¸šà¹„à¸§à¹‰: 3 checkpoints à¸¥à¹ˆà¸²à¸ªà¸¸à¸”

### Final Model
- à¸šà¸±à¸™à¸—à¸¶à¸à¸—à¸µà¹ˆ: `./final_model/`
- à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸›à¸¢à¸±à¸‡: `dlnkgpt/dLNk-gpt-j-6b-agent-v2-phase2`
- à¸”à¸¹à¹„à¸”à¹‰à¸—à¸µà¹ˆ: https://huggingface.co/dlnkgpt/dLNk-gpt-j-6b-agent-v2-phase2

## ğŸ“ˆ Monitoring

### Weights & Biases
- Project: `dLNk-gpt-v2`
- Dashboard: https://wandb.ai/aiattackdlnk/dLNk-gpt-v2

### Telegram Notifications
- à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™à¸—à¸¸à¸ 100 steps
- à¹à¸ªà¸”à¸‡: Step, Loss, Learning Rate, à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸œà¹ˆà¸²à¸™à¹„à¸›, Epoch

## âš ï¸ à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡

1. **à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Colab Pro+** à¸à¸±à¸š A100 GPU
2. **Restart Runtime** à¸«à¸¥à¸±à¸‡à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ dependencies (Cell 1)
3. **à¸à¸£à¸­à¸ tokens** à¹ƒà¸™ Cell 2 à¸à¹ˆà¸­à¸™à¸£à¸±à¸™
4. **à¹„à¸¡à¹ˆà¸„à¸§à¸£à¸›à¸´à¸” browser** à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¹€à¸—à¸£à¸™
5. **à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š compute units** à¸à¹ˆà¸­à¸™à¹€à¸£à¸´à¹ˆà¸¡à¹€à¸—à¸£à¸™

## ğŸ”§ Troubleshooting

### à¸›à¸±à¸à¸«à¸²: Out of Memory
**à¹à¸à¹‰à¹„à¸‚**: à¸¥à¸” `PER_DEVICE_TRAIN_BATCH_SIZE` à¸ˆà¸²à¸ 4 â†’ 2

### à¸›à¸±à¸à¸«à¸²: Loss à¹„à¸¡à¹ˆà¸¥à¸”à¸¥à¸‡
**à¹à¸à¹‰à¹„à¸‚**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² base model à¹‚à¸«à¸¥à¸”à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ à¹à¸¥à¸° data formatting à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡

### à¸›à¸±à¸à¸«à¸²: Telegram à¹„à¸¡à¹ˆà¸ªà¹ˆà¸‡
**à¹à¸à¹‰à¹„à¸‚**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š `TELEGRAM_BOT_TOKEN` à¹à¸¥à¸° `TELEGRAM_CHAT_ID`

### à¸›à¸±à¸à¸«à¸²: à¹€à¸—à¸£à¸™à¸Šà¹‰à¸²
**à¹à¸à¹‰à¹„à¸‚**: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹ƒà¸Šà¹‰ A100 GPU (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ T4 à¸«à¸£à¸·à¸­ V100)

## ğŸ“ Version History

### v2.0 (Current)
- âœ… à¹€à¸£à¹‡à¸§à¸‚à¸¶à¹‰à¸™ 3-4 à¹€à¸—à¹ˆà¸² (~7-8 à¸Šà¸¡.)
- âœ… GPU utilization >80%
- âœ… Early stopping
- âœ… Overfitting prevention
- âœ… Real-time logging

### v1.1 (Previous)
- âŒ à¸Šà¹‰à¸²à¸¡à¸²à¸ (~29 à¸Šà¸¡.)
- âŒ GPU utilization 15%
- âŒ Loss à¹„à¸¡à¹ˆà¸¥à¸”à¸¥à¸‡

## ğŸ“ Support

à¸«à¸²à¸à¸à¸šà¸›à¸±à¸à¸«à¸²:
1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Troubleshooting section
2. à¸”à¸¹ logs à¹ƒà¸™ Colab
3. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š W&B dashboard
4. à¸•à¸´à¸”à¸•à¹ˆà¸­à¸œà¹ˆà¸²à¸™ GitHub Issues

## ğŸ“„ License

MIT License

## ğŸ™ Credits

- Base Model: EleutherAI/gpt-j-6b
- Phase 1 Model: dlnkgpt/dLNk-gpt-j-6b-agent-v1
- Datasets: CodeAlpaca-20k, Python Code Instructions 18k, Code Instructions 120k
- Framework: Hugging Face Transformers, PEFT, TRL

---

**Happy Training! ğŸš€**
